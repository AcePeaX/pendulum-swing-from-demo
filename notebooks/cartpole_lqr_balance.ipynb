{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c29c1b4",
   "metadata": {},
   "source": [
    "# Learning to balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aa2ebb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gymnasium as gym\n",
    "from gymnasium.wrappers import RecordVideo, TimeLimit\n",
    "from stable_baselines3 import PPO\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import trange\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5528a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "current = Path.cwd()\n",
    "\n",
    "# If launched from a subfolder (VS Code), go one level up\n",
    "if (current / \"notebooks\").exists():\n",
    "    PROJECT_ROOT = current\n",
    "else:\n",
    "    PROJECT_ROOT = current.parent\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "DATA_DIR = Path(\"data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b79b34c1",
   "metadata": {},
   "source": [
    "## Set up the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b6508d45",
   "metadata": {},
   "outputs": [],
   "source": [
    "N_STEPS = 1500 # 30 seconds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1c5af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = gym.make(\"CartPole-v1\", max_episode_steps=N_STEPS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02451be",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acepeax/Desktop/Studies/MVA/Robotics/Project/.venv/lib/python3.12/site-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/acepeax/Desktop/Studies/MVA/Robotics/Project/videos folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env_gui = gym.make(\"CartPole-v1\", render_mode=\"rgb_array\", max_episode_steps=N_STEPS)\n",
    "\n",
    "env_gui = RecordVideo(\n",
    "    env_gui,\n",
    "    video_folder=\"videos\",\n",
    "    episode_trigger=lambda ep: True,\n",
    "    name_prefix=\"balance_demo\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c37c91",
   "metadata": {},
   "source": [
    "## Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7b4521c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_episode(env, model, max_steps=1500, deterministic=True):\n",
    "\n",
    "    obs, _ = env.reset()\n",
    "\n",
    "    states = []\n",
    "    actions = []\n",
    "    rewards = []\n",
    "\n",
    "    for _ in range(max_steps):\n",
    "        states.append(obs.copy())\n",
    "\n",
    "        action, _ = model.predict(obs, deterministic=deterministic)\n",
    "        actions.append(action)\n",
    "\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        rewards.append(reward)\n",
    "\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "\n",
    "    return np.array(states), np.array(actions), np.array(rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d3367d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_episode_video(env, model, max_steps=1500, deterministic=True):\n",
    "    obs, _ = env.reset()\n",
    "    done = False\n",
    "    steps = 0\n",
    "\n",
    "    while not done and steps < max_steps:\n",
    "        action, _ = model.predict(obs, deterministic=deterministic)\n",
    "        obs, reward, terminated, truncated, _ = env.step(action)\n",
    "        done = terminated or truncated\n",
    "        steps += 1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aeda48a4",
   "metadata": {},
   "source": [
    "## Getting a good policy for data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afea985e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\"MlpPolicy\", env, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9919fec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4c13dd7d75bf4410b320fdedff13eaf0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines3.ppo.ppo.PPO at 0x7dec09efcc20>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=50000, progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9dab6b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "rollout_episode_video(env_gui, model)\n",
    "env_gui.close()\n",
    "# Look at the videos folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88309937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to: data/ppo_cartpole_balance\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = DATA_DIR / \"test_ppo_cartpole_balance\"\n",
    "\n",
    "model.save(MODEL_PATH)\n",
    "print(\"Model saved to:\", MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b02e478c",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = DATA_DIR / \"ppo_cartpole_balance\"\n",
    "model = PPO.load(MODEL_PATH, env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c22c4ff9",
   "metadata": {},
   "source": [
    "The policy learned to stabilize. But the first 2 seconds, the cartpole drifts a little bit away. We should filterout this from the training data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eab4e520",
   "metadata": {},
   "source": [
    "## Record the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8766d377",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warmup steps: 200\n",
      "Recording steps: 1500\n"
     ]
    }
   ],
   "source": [
    "DT = 0.02           # CartPole timestep (50 Hz)\n",
    "RECORD_TIME = 30.0  # seconds (paper)\n",
    "N_RECORD = int(RECORD_TIME / DT)\n",
    "\n",
    "WARMUP_TIME = 4.0   # seconds to let PPO stabilize before recording\n",
    "N_WARMUP = int(WARMUP_TIME / DT)\n",
    "\n",
    "print(\"Warmup steps:\", N_WARMUP)\n",
    "print(\"Recording steps:\", N_RECORD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b92dc454",
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_30s_episodes_with_data(\n",
    "    model,\n",
    "    n_episodes=5,                 # ✅ number of 30s episodes to record\n",
    "    video_dir=\"videos\",\n",
    "    data_dir=\"data\",\n",
    "    filename=\"ppo_balance_dataset\",\n",
    "    env_id=\"CartPole-v1\",\n",
    "    dt=0.02,\n",
    "):\n",
    "    \"\"\"\n",
    "    Records n_episodes of 30-second episodes using a trained PPO policy\n",
    "    AND saves all observations and actions to a single .npz dataset.\n",
    "    \n",
    "    The .npz file contains:\n",
    "        - observations : (T_total, 4)\n",
    "        - actions      : (T_total,)\n",
    "        - episode_ids  : (T_total,)\n",
    "        - episode_lens : (n_episodes,)\n",
    "        - dt\n",
    "        - env_id\n",
    "    \"\"\"\n",
    "\n",
    "    os.makedirs(video_dir, exist_ok=True)\n",
    "    os.makedirs(data_dir, exist_ok=True)\n",
    "\n",
    "    base_env = gym.make(env_id, render_mode=\"rgb_array\", max_episode_steps=N_STEPS)\n",
    "\n",
    "    env = RecordVideo(\n",
    "        base_env,\n",
    "        video_folder=video_dir,\n",
    "        episode_trigger=lambda ep: True,\n",
    "        name_prefix=filename\n",
    "    )\n",
    "\n",
    "    all_obs = []\n",
    "    all_actions = []\n",
    "    all_episode_ids = []\n",
    "    episode_lens = []\n",
    "\n",
    "    ep = 0  # number of successfull episodes recorded\n",
    "\n",
    "    while ep < n_episodes:\n",
    "\n",
    "        obs, _ = env.reset()\n",
    "        local_obs = []\n",
    "        local_actions = []\n",
    "\n",
    "        success = True\n",
    "\n",
    "        for step in range(N_STEPS):\n",
    "            local_obs.append(obs.copy())\n",
    "\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            local_actions.append(int(action))\n",
    "\n",
    "            obs, _, terminated, truncated, _ = env.step(action)\n",
    "\n",
    "            if terminated:\n",
    "                success = False\n",
    "                break\n",
    "\n",
    "            if truncated and step < N_STEPS - 1:\n",
    "                success = False\n",
    "                break\n",
    "\n",
    "        if success and len(local_obs) == N_STEPS:\n",
    "\n",
    "            all_obs.extend(local_obs)\n",
    "            all_actions.extend(local_actions)\n",
    "            all_episode_ids.extend([ep] * N_STEPS)\n",
    "            episode_lens.append(N_STEPS)\n",
    "\n",
    "            print(f\"✅ Episode {ep} SUCCESS: {N_STEPS} steps recorded\")\n",
    "            ep += 1\n",
    "\n",
    "        else:\n",
    "            print(f\"⚠️ Episode FAILED at {len(local_obs)} steps → retrying...\")\n",
    "\n",
    "    env.close()\n",
    "\n",
    "    all_obs = np.array(all_obs)\n",
    "    all_actions = np.array(all_actions)\n",
    "    all_episode_ids = np.array(all_episode_ids)\n",
    "    episode_lens = np.array(episode_lens)\n",
    "\n",
    "    save_path = os.path.join(data_dir, f\"{filename}.npz\")\n",
    "    np.savez(\n",
    "        save_path,\n",
    "        observations=all_obs,\n",
    "        actions=all_actions,\n",
    "        episode_ids=all_episode_ids,\n",
    "        episode_lens=episode_lens,\n",
    "        dt=dt,\n",
    "        env_id=env_id,\n",
    "        n_episodes=n_episodes,\n",
    "        steps_per_episode=N_STEPS\n",
    "    )\n",
    "\n",
    "    print(\"FINAL DATASET SAVED\")\n",
    "    print(\"Observations shape :\", all_obs.shape)\n",
    "    print(\"Actions shape      :\", all_actions.shape)\n",
    "    print(\"Episode ids shape  :\", all_episode_ids.shape)\n",
    "    print(\"Episode lengths    :\", episode_lens)\n",
    "    print(\"Saved to           :\", save_path)\n",
    "\n",
    "    return all_obs, all_actions, all_episode_ids, episode_lens\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ad73701e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Episode 0 SUCCESS: 1500 steps recorded\n",
      "✅ Episode 1 SUCCESS: 1500 steps recorded\n",
      "✅ Episode 2 SUCCESS: 1500 steps recorded\n",
      "✅ Episode 3 SUCCESS: 1500 steps recorded\n",
      "✅ Episode 4 SUCCESS: 1500 steps recorded\n",
      "✅ Episode 5 SUCCESS: 1500 steps recorded\n",
      "✅ Episode 6 SUCCESS: 1500 steps recorded\n",
      "✅ Episode 7 SUCCESS: 1500 steps recorded\n",
      "✅ Episode 8 SUCCESS: 1500 steps recorded\n",
      "✅ Episode 9 SUCCESS: 1500 steps recorded\n",
      "FINAL DATASET SAVED\n",
      "Observations shape : (15000, 4)\n",
      "Actions shape      : (15000,)\n",
      "Episode ids shape  : (15000,)\n",
      "Episode lengths    : [1500 1500 1500 1500 1500 1500 1500 1500 1500 1500]\n",
      "Saved to           : data/ppo_balance_clean_30s.npz\n"
     ]
    }
   ],
   "source": [
    "X, U, ep_ids, ep_lens = record_30s_episodes_with_data(\n",
    "    model,\n",
    "    n_episodes=10,\n",
    "    video_dir=\"videos\",\n",
    "    data_dir=\"data\",\n",
    "    filename=\"ppo_balance_clean_30s\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96ee2e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
