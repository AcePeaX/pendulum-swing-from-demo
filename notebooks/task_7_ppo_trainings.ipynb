{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "276896fc",
   "metadata": {},
   "source": [
    "# PPO training for Task 7 pendulum\n",
    "\n",
    "Reproduces the PPO workflow from `task_2_lqr_balance_data_gen.ipynb`, but runs directly on the custom PyBullet + Pinocchio environment implemented in `scripts/task_7_env.py`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8cc2cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from stable_baselines3 import PPO\n",
    "from stable_baselines3.common.monitor import Monitor\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv\n",
    "from gymnasium.wrappers import RecordVideo\n",
    "import control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "36b9f767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project root: /home/acepeax/Desktop/Studies/MVA/Robotics/Project\n"
     ]
    }
   ],
   "source": [
    "current = Path.cwd()\n",
    "\n",
    "if (current / 'notebooks').exists():\n",
    "    PROJECT_ROOT = current\n",
    "else:\n",
    "    PROJECT_ROOT = current.parent\n",
    "\n",
    "os.chdir(PROJECT_ROOT)\n",
    "\n",
    "import sys\n",
    "if str(PROJECT_ROOT) not in sys.path:\n",
    "    sys.path.insert(0, str(PROJECT_ROOT))\n",
    "\n",
    "from scripts.task_7_env import Task7PendulumEnv, Y_MAX\n",
    "\n",
    "DATA_DIR = Path('data')\n",
    "MODELS_DIR = DATA_DIR\n",
    "for directory in (DATA_DIR, MODELS_DIR):\n",
    "    directory.mkdir(exist_ok=True)\n",
    "\n",
    "print('Project root:', PROJECT_ROOT)\n",
    "\n",
    "DATASET_SIM_SUBSTEPS = 6\n",
    "DATASET_DURATION_S = 30.0\n",
    "DATASET_VIDEO_DIR = Path('videos/task7_dataset')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad820117",
   "metadata": {},
   "source": [
    "## Environment helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8395dadc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation space: Box(-inf, inf, (14,), float32)\n",
      "Action space: Discrete(3)\n"
     ]
    }
   ],
   "source": [
    "MAX_STEPS = 1000\n",
    "SHOULD_BALANCE = True\n",
    "SIM_SUBSTEPS = 12\n",
    "\n",
    "def make_task7_env(gui=False, should_balance=SHOULD_BALANCE, sim_substeps=SIM_SUBSTEPS):\n",
    "    def _init():\n",
    "        env = Task7PendulumEnv(\n",
    "            max_steps=MAX_STEPS,\n",
    "            should_balance=should_balance,\n",
    "            gui=gui,\n",
    "            sim_substeps=sim_substeps,\n",
    "        )\n",
    "        return Monitor(env)\n",
    "    return _init\n",
    "\n",
    "train_env = DummyVecEnv([make_task7_env(gui=False, should_balance=SHOULD_BALANCE)])\n",
    "print('Observation space:', train_env.observation_space)\n",
    "print('Action space:', train_env.action_space)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "60c0dec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rollout_episode(env, model, max_steps=MAX_STEPS, deterministic=True):\n",
    "    obs, _ = env.reset()\n",
    "    rewards = []\n",
    "    infos = []\n",
    "    for _ in range(max_steps):\n",
    "        action, _ = model.predict(obs, deterministic=deterministic)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        infos.append(info)\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    return np.array(rewards), infos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "245c3c13",
   "metadata": {},
   "source": [
    "## Train PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84dd7427",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = PPO(\n",
    "    policy='MlpPolicy',\n",
    "    env=train_env,\n",
    "    verbose=0,\n",
    "    n_steps=2048,\n",
    "    batch_size=256,\n",
    "    gamma=0.99,\n",
    "    gae_lambda=0.95,\n",
    "    ent_coef=0.0,\n",
    "    learning_rate=3e-4,\n",
    "    clip_range=0.2,\n",
    "    tensorboard_log='runs/task7_ppo',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d885b93",
   "metadata": {},
   "outputs": [],
   "source": [
    "TOTAL_TIMESTEPS = 200_000\n",
    "model.learn(total_timesteps=TOTAL_TIMESTEPS, progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0b9ec2a",
   "metadata": {},
   "source": [
    "## Save / load the trained policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39cbd6f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to data/test_ppo_robot_arm_balance\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = MODELS_DIR / 'test_ppo_robot_arm_balance'\n",
    "model.save(MODEL_PATH)\n",
    "print('Model saved to', MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0019c8ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = MODELS_DIR / 'ppo_robot_arm_balance'\n",
    "model = PPO.load(MODEL_PATH, train_env)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dbd70fe",
   "metadata": {},
   "source": [
    "train_env.close()\n",
    "\n",
    "EVAL_RECORD_VIDEO = False\n",
    "EVAL_VIDEO_DIR = Path('videos/task7_eval_rollouts')\n",
    "\n",
    "def rollout_episode(env, model, max_steps=MAX_STEPS, deterministic=True):\n",
    "    obs, _ = env.reset()\n",
    "    rewards = []\n",
    "    infos = []\n",
    "    for _ in range(max_steps):\n",
    "        action, _ = model.predict(obs, deterministic=deterministic)\n",
    "        obs, reward, terminated, truncated, info = env.step(action)\n",
    "        rewards.append(reward)\n",
    "        infos.append(info)\n",
    "        if terminated or truncated:\n",
    "            break\n",
    "    return np.array(rewards), infos\n",
    "\n",
    "if EVAL_RECORD_VIDEO:\n",
    "    EVAL_VIDEO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "    base_eval_env = Task7PendulumEnv(\n",
    "        max_steps=MAX_STEPS,\n",
    "        should_balance=SHOULD_BALANCE,\n",
    "        gui=False,\n",
    "        sim_substeps=SIM_SUBSTEPS,\n",
    "        render_mode='rgb_array',\n",
    "    )\n",
    "    eval_env = RecordVideo(\n",
    "        base_eval_env,\n",
    "        video_folder=str(EVAL_VIDEO_DIR),\n",
    "        name_prefix='task7_eval',\n",
    "        episode_trigger=lambda ep: True,\n",
    "    )\n",
    "else:\n",
    "    eval_env = Task7PendulumEnv(\n",
    "        max_steps=MAX_STEPS, should_balance=SHOULD_BALANCE, gui=True, sim_substeps=SIM_SUBSTEPS\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "65319fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Intel\n",
      "GL_RENDERER=Mesa Intel(R) Iris(R) Xe Graphics (RPL-U)\n",
      "GL_VERSION=4.6 (Core Profile) Mesa 25.0.7-0ubuntu0.24.04.1\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.6 (Core Profile) Mesa 25.0.7-0ubuntu0.24.04.1\n",
      "Vendor = Intel\n",
      "Renderer = Mesa Intel(R) Iris(R) Xe Graphics (RPL-U)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n"
     ]
    }
   ],
   "source": [
    "train_env.close()\n",
    "\n",
    "eval_env = Task7PendulumEnv(\n",
    "    max_steps=MAX_STEPS, should_balance=SHOULD_BALANCE, gui=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782f6673",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards, infos = rollout_episode(eval_env, model)\n",
    "print('Episode length:', len(rewards))\n",
    "print('Total reward:', rewards.sum())\n",
    "print('Final info:', infos[-1] if infos else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d77f674",
   "metadata": {},
   "source": [
    "## Export rollouts for datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63a97ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_VIDEO_DIR.mkdir(parents=True, exist_ok=True)\n",
    "BASE_BULLET_DT = 1.0 / 240.0\n",
    "\n",
    "def _episode_steps(duration_s, sim_substeps):\n",
    "    return max(1, int(round(duration_s / (sim_substeps * BASE_BULLET_DT))))\n",
    "\n",
    "def record_task7_dataset(\n",
    "    model,\n",
    "    n_episodes=5,\n",
    "    should_balance=SHOULD_BALANCE,\n",
    "    filename='task7_ppo_dataset',\n",
    "    sim_substeps=DATASET_SIM_SUBSTEPS,\n",
    "    episode_duration_s=DATASET_DURATION_S,\n",
    "    video_folder=DATASET_VIDEO_DIR,\n",
    "    record_video=True,\n",
    "):\n",
    "    video_folder = Path(video_folder)\n",
    "    video_folder.mkdir(parents=True, exist_ok=True)\n",
    "    max_steps = _episode_steps(episode_duration_s, sim_substeps)\n",
    "    print(f'Recording {n_episodes} episodes of {episode_duration_s}s (~{max_steps} env steps)')\n",
    "    base_env = Task7PendulumEnv(\n",
    "        max_steps=max_steps,\n",
    "        should_balance=should_balance,\n",
    "        gui=False,\n",
    "        render_mode=\"rgb_array\",\n",
    "        sim_substeps=sim_substeps,\n",
    "    )\n",
    "    env = RecordVideo(\n",
    "        base_env,\n",
    "        video_folder=str(video_folder),\n",
    "        name_prefix=filename,\n",
    "        episode_trigger=(lambda ep: ep == 0) if record_video else (lambda ep: False),\n",
    "    )\n",
    "    all_obs, all_actions, all_rewards, episode_ids = [], [], [], []\n",
    "    recorded = 0\n",
    "    while recorded < n_episodes:\n",
    "        obs, _ = env.reset()\n",
    "        local_obs, local_actions, local_rewards = [], [], []\n",
    "        success = True\n",
    "        for step in tqdm(range(max_steps)):\n",
    "            local_obs.append(obs.copy())\n",
    "            action, _ = model.predict(obs, deterministic=True)\n",
    "            action = int(action)\n",
    "            local_actions.append(action)\n",
    "            obs, reward, terminated, truncated, info = env.step(action)\n",
    "            local_rewards.append(reward)\n",
    "            if terminated or truncated:\n",
    "                success = info.get('success', False) and not info.get('failure', False)\n",
    "                break\n",
    "        if success and len(local_obs) == max_steps:\n",
    "            all_obs.extend(local_obs)\n",
    "            all_actions.extend(local_actions)\n",
    "            all_rewards.extend(local_rewards)\n",
    "            episode_ids.extend([recorded] * len(local_obs))\n",
    "            recorded += 1\n",
    "            print(f'Recorded episode {recorded}/{n_episodes}')\n",
    "        else:\n",
    "            print('[WARNING] Episode failed, retrying...')\n",
    "    env.close()\n",
    "    save_path = DATA_DIR / f'{filename}.npz'\n",
    "    np.savez(\n",
    "        save_path,\n",
    "        observations=np.array(all_obs, dtype=np.float32),\n",
    "        actions=np.array(all_actions, dtype=np.int64),\n",
    "        rewards=np.array(all_rewards, dtype=np.float32),\n",
    "        episode_ids=np.array(episode_ids, dtype=np.int32),\n",
    "        max_steps=max_steps,\n",
    "        sim_substeps=sim_substeps,\n",
    "        episode_duration_s=episode_duration_s,\n",
    "    )\n",
    "    print('Dataset saved to', save_path)\n",
    "    return save_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c4ece55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/acepeax/Desktop/Studies/MVA/Robotics/Project/.venv/lib/python3.12/site-packages/gymnasium/wrappers/rendering.py:293: UserWarning: \u001b[33mWARN: Overwriting existing videos at /home/acepeax/Desktop/Studies/MVA/Robotics/Project/videos/task7_dataset folder (try specifying a different `video_folder` for the `RecordVideo` wrapper if this is not desired)\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recording 7 episodes of 30.0s (~1200 env steps)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1199/1200 [00:02<00:00, 549.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded episode 1/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1199/1200 [00:02<00:00, 539.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded episode 2/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1199/1200 [00:02<00:00, 482.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded episode 3/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1199/1200 [00:02<00:00, 446.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded episode 4/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1199/1200 [00:02<00:00, 459.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded episode 5/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1199/1200 [00:02<00:00, 448.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded episode 6/7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 1199/1200 [00:02<00:00, 458.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recorded episode 7/7\n",
      "Dataset saved to data/task7_ppo_balance_rollouts.npz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dataset_path = record_task7_dataset(\n",
    "    model,\n",
    "    n_episodes=7,\n",
    "    filename='task7_ppo_balance_rollouts',\n",
    "    sim_substeps=6,\n",
    "    episode_duration_s=30.0,\n",
    "    video_folder=DATASET_VIDEO_DIR,\n",
    "    record_video=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c4d2dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    train_env.close()\n",
    "except:\n",
    "    pass\n",
    "try:\n",
    "    train_env.close()\n",
    "except:\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76e8401",
   "metadata": {},
   "source": [
    "## Task 7 dataset inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a61c5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observations: (8400, 14)\n",
      "Actions: (8400,)\n",
      "Episodes IDs: (8400,)\n",
      "sim_substeps: 6 episode_duration: 30.0 max_steps: 1200\n"
     ]
    }
   ],
   "source": [
    "DATASET_FILE = DATA_DIR / 'task7_ppo_balance_rollouts.npz'\n",
    "if not DATASET_FILE.exists():\n",
    "    raise FileNotFoundError(f'Missing dataset: {DATASET_FILE}')\n",
    "dataset = np.load(DATASET_FILE)\n",
    "observations = dataset['observations']\n",
    "actions = dataset['actions']\n",
    "episode_ids = dataset['episode_ids']\n",
    "sim_substeps_ds = int(dataset.get('sim_substeps', DATASET_SIM_SUBSTEPS))\n",
    "episode_duration_ds = float(dataset.get('episode_duration_s', DATASET_DURATION_S))\n",
    "max_steps_ds = int(dataset.get('max_steps', observations.shape[0]))\n",
    "print('Observations:', observations.shape)\n",
    "print('Actions:', actions.shape)\n",
    "print('Episodes IDs:', episode_ids.shape)\n",
    "print('sim_substeps:', sim_substeps_ds, 'episode_duration:', episode_duration_ds, 'max_steps:', max_steps_ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62a50d29",
   "metadata": {},
   "source": [
    "### Build transitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a6f17fc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transitions: (8393, 14) (8393, 1) (8393, 14)\n"
     ]
    }
   ],
   "source": [
    "same_episode = episode_ids[1:] == episode_ids[:-1]\n",
    "X = observations[:-1][same_episode]\n",
    "X_next = observations[1:][same_episode]\n",
    "ACTION_VALUES = np.array([-Y_MAX, 0.0, Y_MAX], dtype=np.float32)\n",
    "U = ACTION_VALUES[actions[:-1][same_episode]].reshape(-1, 1)\n",
    "print('Transitions:', X.shape, U.shape, X_next.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4c2c57f",
   "metadata": {},
   "source": [
    "### Keep samples near the upright equilibrium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7d8fa967",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Local samples: 7273 / 8393\n"
     ]
    }
   ],
   "source": [
    "theta = X[:, 0]\n",
    "theta_dot = X[:, 1]\n",
    "local_mask = (np.abs(theta) < 0.3) & (np.abs(theta_dot) < 1.5)\n",
    "X_loc = X[local_mask]\n",
    "U_loc = U[local_mask]\n",
    "X_next_loc = X_next[local_mask]\n",
    "print('Local samples:', X_loc.shape[0], '/', X.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bac7e7d",
   "metadata": {},
   "source": [
    "### Fit a linear model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0c32acf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A shape: (14, 14)\n",
      "B shape: (14, 1)\n"
     ]
    }
   ],
   "source": [
    "nx = X_loc.shape[1]\n",
    "nu = U_loc.shape[1]\n",
    "Z = np.hstack([X_loc, U_loc])\n",
    "Y = X_next_loc\n",
    "W, *_ = np.linalg.lstsq(Z, Y, rcond=None)\n",
    "A_lin = W[:nx, :].T\n",
    "B_lin = W[nx:, :].T\n",
    "print('A shape:', A_lin.shape)\n",
    "print('B shape:', B_lin.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d50394c",
   "metadata": {},
   "source": [
    "### Design an LQR controller on the linearized model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71284716",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K shape: (1, 14)\n",
      "Eigenvalues: [-0.55807994+0.j         -0.12043677+0.j          0.01876407+0.j\n",
      "  0.20117272+0.j          0.31488259+0.08737926j  0.31488259-0.08737926j\n",
      "  0.33036833+0.j          0.7628735 +0.26921604j  0.7628735 -0.26921604j\n",
      "  0.94788135+0.10315928j  0.94788135-0.10315928j  0.88290375+0.j\n",
      "  0.9832996 +0.j          0.99999873+0.j        ]\n"
     ]
    }
   ],
   "source": [
    "state_weights = np.ones(nx) * 0.1\n",
    "state_weights[0] = 8.0\n",
    "state_weights[1] = 1.0\n",
    "Q = np.diag(state_weights)\n",
    "R = np.array([[0.5]])\n",
    "K_lqr, S_lqr, eigvals_lqr = control.dlqr(A_lin, B_lin, Q, R)\n",
    "print('K shape:', K_lqr.shape)\n",
    "print('Eigenvalues:', eigvals_lqr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "689d5c93",
   "metadata": {},
   "source": [
    "### Rollout the LQR controller in the simulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cee67e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "argc=2\n",
      "argv[0] = --unused\n",
      "argv[1] = --start_demo_name=Physics Server\n",
      "ExampleBrowserThreadFunc started\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "X11 functions dynamically loaded using dlopen/dlsym OK!\n",
      "Creating context\n",
      "Created GL 3.3 context\n",
      "Direct GLX rendering context obtained\n",
      "Making context current\n",
      "GL_VENDOR=Intel\n",
      "GL_RENDERER=Mesa Intel(R) Iris(R) Xe Graphics (RPL-U)\n",
      "GL_VERSION=4.6 (Core Profile) Mesa 25.0.7-0ubuntu0.24.04.1\n",
      "GL_SHADING_LANGUAGE_VERSION=4.60\n",
      "pthread_getconcurrency()=0\n",
      "Version = 4.6 (Core Profile) Mesa 25.0.7-0ubuntu0.24.04.1\n",
      "Vendor = Intel\n",
      "Renderer = Mesa Intel(R) Iris(R) Xe Graphics (RPL-U)\n",
      "b3Printf: Selected demo: Physics Server\n",
      "startThreads creating 1 threads.\n",
      "starting thread 0\n",
      "started thread 0 \n",
      "MotionThreadFunc thread started\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n",
      "ven = Intel\n",
      "Workaround for some crash in the Intel OpenGL driver on Linux/Ubuntu\n"
     ]
    }
   ],
   "source": [
    "class Task7LQRPolicy:\n",
    "    def __init__(self, K):\n",
    "        self.K = K\n",
    "    def predict(self, obs, deterministic=True):\n",
    "        u = float(-(self.K @ obs.reshape(-1, 1)))\n",
    "        clipped = np.clip(u, ACTION_VALUES.min(), ACTION_VALUES.max())\n",
    "        idx = int(np.argmin(np.abs(ACTION_VALUES - clipped)))\n",
    "        return idx, None\n",
    "\n",
    "lqr_policy = Task7LQRPolicy(K_lqr)\n",
    "eval_env_lqr = Task7PendulumEnv(gui=True, should_balance=SHOULD_BALANCE, sim_substeps=SIM_SUBSTEPS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dc0d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "rewards_lqr, infos_lqr = rollout_episode(eval_env_lqr, lqr_policy)\n",
    "print('LQR episode length:', len(rewards_lqr))\n",
    "print('LQR total reward:', rewards_lqr.sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a282f04b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "numActiveThreads = 0\n",
      "stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "Thread TERMINATED\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n",
      "finished\n",
      "numActiveThreads = 0\n",
      "btShutDownExampleBrowser stopping threads\n",
      "Thread with taskId 0 exiting\n",
      "destroy semaphore\n",
      "semaphore destroyed\n",
      "Thread TERMINATED\n",
      "destroy main semaphore\n",
      "main semaphore destroyed\n"
     ]
    }
   ],
   "source": [
    "eval_env_lqr.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
